{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import moviepy.editor as moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip=moviepy.VideoFileClip(\"firearch.avi\")\n",
    "#clip.write_videofile(\"sample.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('firearch.avi')\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "#fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "car_counter = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    frame = imutils.resize(frame, width=640)\n",
    "    # Especificamos los puntos extremos del área a analizar\n",
    "    #area_pts = np.array([[330, 216], [frame.shape[1]-80, 216], [frame.shape[1]-80, 271], [330, 271]])\n",
    "    area_pts = np.array([[350, 350], [frame.shape[1]-80, 250], [frame.shape[1]-80, 250], [350, 250]])\n",
    "\n",
    "    imAux = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    imAux = cv2.drawContours(imAux, [area_pts], -1, (255), -1)\n",
    "    image_area = cv2.bitwise_and(frame,frame, mask=imAux)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendremos la imagen binaria donde la región en blanco representa\n",
    "# la existencia de movimiento\n",
    "fgmask = fgbg.apply(image_area)\n",
    "fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "fgmask = cv2.dilate(fgmask, None, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos los contornos presentes de fgmask, para luego basándonos\n",
    "# en su área poder determinar si existe movimiento (autos)\n",
    "cnts = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in cnts:\n",
    "    if cv2.contourArea(cnt) > 1500:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el auto ha cruzado entre 440 y 460 abierto, se incrementará\n",
    "# en 1 el contador de autos\n",
    "if 440 < (x + w) < 460:\n",
    "    car_counter = car_counter + 1\n",
    "    cv2.line(frame, (450, 216), (450, 271), (0, 255, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin del video\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('firearch.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el archivo de video\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Fin del video\")\n",
    "            break\n",
    "\n",
    "        # Resto del código\n",
    "        cv2.drawContours(frame, [area_pts], -1, (255, 0, 255), 2)\n",
    "        cv2.line(frame, (450, 216), (450, 271), (0, 255, 255), 1)\n",
    "        cv2.rectangle(frame, (frame.shape[1]-70, 215), (frame.shape[1]-5, 270), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, str(car_counter), (frame.shape[1]-55, 250),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)\n",
    "        cv2.imshow('frame', frame)\n",
    "        k = cv2.waitKey(70) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin del video\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('firearch.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el archivo de video\")\n",
    "else:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Fin del video\")\n",
    "            break\n",
    "\n",
    "        # Definir las coordenadas que se desean mostrar\n",
    "        coords = [(100, 100), (200, 200), (300, 300),(960,840),(960,840),(350, 350),(350, 250),(570,700),(570,500),(1200,600),(1100,450)]\n",
    "\n",
    "        # Dibujar las coordenadas en la imagen\n",
    "        for coord in coords:\n",
    "            cv2.circle(frame, coord, 5, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f'({coord[0]}, {coord[1]})', coord, \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Mostrar la imagen resultante\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Esperar a que se presione la tecla 'q' para salir del bucle\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
